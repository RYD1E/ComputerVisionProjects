{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852b55f5",
   "metadata": {},
   "source": [
    "# A simple CV based volume controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad432de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "from pycaw.pycaw import AudioUtilities, ISimpleAudioVolume\n",
    "import numpy as np\n",
    "  \n",
    "def fingup(lml,finindex):\n",
    "    re=[]\n",
    "    if lml[4][1]<lml[3][1]:\n",
    "        re.append(1)\n",
    "    else:\n",
    "        re.append(0)\n",
    "    for i in range(len(finindex)):\n",
    "        if lml[finindex[i]][2]<lml[finindex[i]-2][2]:\n",
    "            re.append(1)\n",
    "        else:\n",
    "            re.append(0)\n",
    "    return re\n",
    "    \n",
    "def handpos(results, img, draw=True):\n",
    "    lml=[]\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handlms in results.multi_hand_landmarks:\n",
    "            mpdraw.draw_landmarks(img, handlms,mpHands.HAND_CONNECTIONS)\n",
    "            for _id, lm in enumerate(handlms.landmark):\n",
    "                #print(_id,lm)\n",
    "                #to know the center of the location of the points\n",
    "                h,w,c=img.shape\n",
    "                cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                lml.append([_id,cx,cy])\n",
    "                #if draw:\n",
    "                    #cv2.circle(img,(cx,cy),5,(255,100,200),cv2.FILLED)\n",
    "    return lml\n",
    "def getdist(lml,p1,p2,img,draw=True,rad=12,thic=3):\n",
    "    x1,y1=lml[p1][1:]\n",
    "    x2,y2=lml[p2][1:]\n",
    "    c1,c2=(x1+x2) //2,(y1+y2)//2\n",
    "           \n",
    "    if draw:\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(5,100,200),thic)\n",
    "        cv2.circle(img,(x1,y1),rad,(5,100,200),cv2.FILLED)\n",
    "        cv2.circle(img,(x2,y2),rad,(5,100,200),cv2.FILLED)\n",
    "        cv2.circle(img,(c1,c2),rad-2,(255,0,25),cv2.FILLED)\n",
    "    dist= math.hypot(x2-x1,y2-y1)\n",
    "    return dist,img,[x1,x2,y1,y2,c1,c2]\n",
    "def vol(volu):\n",
    "    volume.SetMasterVolumeLevel(volu, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e34e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap= cv2.VideoCapture(0)\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands= mpHands.Hands()\n",
    "mpdraw= mp.solutions.drawing_utils    #for drawing dots and connections\n",
    "lmltop=[]\n",
    "finindex=[8,12,16,20]\n",
    "\n",
    "ptime=0\n",
    "ctime=0\n",
    "\n",
    "ndist=0\n",
    "\n",
    "\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(\n",
    "    IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "volRange = volume.GetVolumeRange()\n",
    "minVol = volRange[0]\n",
    "maxVol = volRange[1]\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img1 = cap.read()\n",
    "    img = cv2.flip(img1, 1)\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    #print( results.multi_hand_landmarks)\n",
    "    #hand land marks\n",
    "    volper=int(volume.GetMasterVolumeLevelScalar()*100)\n",
    "    volbar = np.interp(volper, [0, 100], [400, 150])\n",
    "\n",
    "    lml=handpos(results,img)\n",
    "    cv2.rectangle(img, (40,140), (95, 410), (255,255,255), 3)\n",
    "    cv2.putText(img,'Gesture-based volume Controller',(40,40),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "    cv2.putText(img,str(int(volper))+'%',(28,120),cv2.FONT_HERSHEY_PLAIN,3,(255,255,255),3)\n",
    "    cv2.rectangle(img, (50,int(volbar)), (85, 400), (0,255,0), cv2.FILLED)\n",
    "    if len(lml) !=0:\n",
    "        finup=fingup(lml,finindex)\n",
    "        if finup == [1,1,0,0,0]:\n",
    "            ndist, img, pt=getdist(lml,4,8,img)\n",
    "            volu = np.interp(ndist, [50, 150], [minVol,maxVol])\n",
    "            \n",
    "            if ndist > 50:\n",
    "                vol(volu)\n",
    "    ctime=time.time()\n",
    "    fps=1/(ctime-ptime)\n",
    "    ptime=ctime\n",
    "    \n",
    "    #cv2.putText(img,str(int(fps)),(10,70),cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)\n",
    "    cv2.imshow(\"Image\",img)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
